{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/projects/ai/audio/bark/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#%pip install resampy\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "from bark.api import text_to_semantic, semantic_to_waveform, generate_audio\n",
    "from bark.generation import SAMPLE_RATE, generate_text_semantic, SEMANTIC_RATE_HZ\n",
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile\n",
    "import resampy\n",
    "import sys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic dataset\n",
    "\n",
    "This notebook creates a synthetic dataset of audio: semantic tokens pairs based on voice line prompts from Mozilla CommonVoice. The purpose of this dataset is to reconstruct the Bark semantic tokens codebook, which will enable us to convert ground-truth audio to a semantic prompt for use in fine-tuning and voice cloning. This notebook provides step-by-step instructions for creating the synthetic dataset and saving it in Fairseq dataset format. Let's get started!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For prototyping, we generate voice lines based on metadata from an old version of the [Mozilla CommonVoice dataset](https://www.kaggle.com/datasets/nickj26/common-voice-corpus-1?resource=download&select=validated.tsv) metadata. This is far from ideal; down the pike, we need a much more larger dataset with more diverse voice lines, including multilingual and non-spoken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['client_id', 'path', 'sentence', 'up_votes', 'down_votes', 'age',\n",
       "       'gender', 'accent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CV_METADATA_PATH = '../datasets/validated.tsv'\n",
    "df = pd.read_csv(CV_METADATA_PATH, sep=\"\\t\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['To give chalk for cheese', 'Judge may not think so.',\n",
       "       'I have already described the appearance of that colossal bulk which was embedded in the ground.',\n",
       "       ..., \"How's the forecast for VI\",\n",
       "       'Please look up the Jenny of the Prairie television show.',\n",
       "       'Find me the creative work The Pickwick Papers'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview\n",
    "lines = df[\"sentence\"].unique()\n",
    "lines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are enough English lines for ~25 hours of audio with unique voice lines; _hopefully_ we'll need less than that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force cu118 generation if available\n",
    "#%pip install torch torchaudio --force --extra-index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_to_generate = 3 * 60\n",
    "# Line index in commonvoice to start with. Useful when resuming\n",
    "start_line = 10307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture log\n",
    "minutes_generated = 0\n",
    "\n",
    "label_file = open('../datasets/en/labels.txt', \"a\")\n",
    "manifest_file = open('../datasets/en/manifest.tsv', 'a')\n",
    "# Give TSV header at beginning.\n",
    "# No, this isn't robust. Too bad!\n",
    "if start_line == 0:\n",
    "    manifest_file.write(str(os.path.abspath(\"../datasets/en\")) + \"\\n\")\n",
    "\n",
    "# Because HuBERT is trained on 16khz data\n",
    "OUTPUT_SAMPLE_RATE = 16_000\n",
    "resampler = torchaudio.transforms.Resample(orig_freq=SAMPLE_RATE, new_freq=OUTPUT_SAMPLE_RATE)\n",
    "\n",
    "for i, line in enumerate(lines[start_line:]):\n",
    "    try:\n",
    "        semantic_tokens = generate_text_semantic(text=line, temp=1)\n",
    "        waveform_arr = semantic_to_waveform(semantic_tokens)\n",
    "\n",
    "        # Persist sequence to new line\n",
    "        label_file.write(' '.join(list(map(str, semantic_tokens.tolist()))) + \"\\n\")\n",
    "        label_file.flush()\n",
    "\n",
    "        # Downsample generated audio to 16khz and save \n",
    "        waveform_tensor = torch.from_numpy(waveform_arr)\n",
    "        resampled_tensor = resampler(waveform_tensor).unsqueeze(0)\n",
    "        wav_fname = f\"en_{start_line + i}_{line}.wav\"\n",
    "        wav_filepath = f\"../datasets/en/{wav_fname}\"\n",
    "        torchaudio.save(wav_filepath, resampled_tensor, OUTPUT_SAMPLE_RATE)\n",
    "\n",
    "        # Log info to manifest\n",
    "        seconds_generated = len(semantic_tokens) / SEMANTIC_RATE_HZ\n",
    "        manifest_file.write(f\"{wav_fname}\\t{resampled_tensor.shape[1]}\" + \"\\n\")\n",
    "        manifest_file.flush()\n",
    "\n",
    "        # Cutoff when sufficient data\n",
    "        minutes_generated += seconds_generated / 60\n",
    "        print(f\"Minutes of audio: {minutes_generated}\")\n",
    "        if minutes_generated > minutes_to_generate:\n",
    "            break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONE-OFF: Convert existing model to new\n",
    "\n",
    "DELETE THIS after finishing and verifying correctness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "import glob\n",
    "\n",
    "old_folder_path = '../datasets/en_old/'\n",
    "search_pattern = os.path.join(old_folder_path, \"*.wav\")\n",
    "\n",
    "label_file = open(f'{old_folder_path}/labels.txt', \"w\")\n",
    "manifest_file = open(f'{old_folder_path}/manifest.tsv', 'w')\n",
    "manifest_file.write(str(os.path.abspath(\"../datasets/en_old\")) + \"\\n\")\n",
    "\n",
    "OUTPUT_SAMPLE_RATE = 16_000\n",
    "resampler = torchaudio.transforms.Resample(orig_freq=SAMPLE_RATE, new_freq=OUTPUT_SAMPLE_RATE)\n",
    "\n",
    "for wav_filename in glob.glob(search_pattern):\n",
    "    # Load file\n",
    "    basename = os.path.basename(wav_filename)\n",
    "    wav, sr = torchaudio.load(wav_filename)\n",
    "\n",
    "    # Convert to 16khz and overwrite original\n",
    "    if sr != 16_000:\n",
    "        resampled_tensor = resampler(wav)\n",
    "        torchaudio.save(wav_filename, resampled_tensor, OUTPUT_SAMPLE_RATE)\n",
    "        manifest_file.write(f\"{basename}\\t{resampled_tensor.shape[1]}\\n\")\n",
    "    else:\n",
    "        manifest_file.write(f\"{basename}\\t{wav.shape[1]}\\n\")\n",
    "\n",
    "    \n",
    "    manifest_file.flush()\n",
    "    semantic_history = np.load(\n",
    "        os.path.join(old_folder_path, f\"{basename[2:-4]}.npz\")\n",
    "    )[\"tokens\"]\n",
    "    wav_length_seconds = len(semantic_history) / 49.9\n",
    "\n",
    "    # Add manifest entry\n",
    "\n",
    "    # Write tokens to label file\n",
    "    label_file.write(f'{\" \".join(list(map(str, semantic_history.tolist())))}\\n')\n",
    "    label_file.flush()\n",
    "\n",
    "    # Try only one for now\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "790f29072abc26870ccb3736e8ffe1b6fbe9bdb3e500c5faf362e772e52ef00f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
